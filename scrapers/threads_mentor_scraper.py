import asyncio
from playwright.async_api import async_playwright
import json

async def scrape_threads_robust():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        # æ¨¡æ“¬æ›´çœŸå¯¦çš„ç€è¦½å™¨
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        )
        page = await context.new_page()

        print("ğŸš€ æ­£åœ¨é€²å…¥ Threads æœå°‹ã€æ„Ÿæƒ…ã€ç›¸é—œè¨è«–...")
        await page.goto("https://www.threads.net/search?q=%E6%84%9F%E6%83%85%E5%BB%BA%E8%AD%B0")
        
        # å¢åŠ åˆå§‹ç­‰å¾…æ™‚é–“ï¼Œè®“é é¢å®Œå…¨æ¸²æŸ“
        await page.wait_for_load_state("networkidle")
        await page.wait_for_timeout(5000)

        mentor_dataset = []
        seen_text = set() # é¿å…é‡è¤‡æŠ“å–

        for i in range(10): # æ²å‹• 10 æ¬¡
            print(f"ğŸ“„ æ²å‹•ä¸¦æƒæä¸­ (ç¬¬ {i+1} æ¬¡)...")
            
            # ğŸ’¡ æš´åŠ›è§£ï¼šæŠ“å–æ‰€æœ‰ div æ¨™ç±¤ä¸­çš„æ–‡å­—
            elements = await page.query_selector_all('div')
            for el in elements:
                text = await el.inner_text()
                text = text.strip()
                
                # ç¯©é¸é‚è¼¯ï¼š
                # 1. é•·åº¦å¤§æ–¼ 50 å€‹å­— (é€šå¸¸æ˜¯å¿ƒå¾—æˆ–å»ºè­°)
                # 2. åŒ…å«é—œéµå­—
                # 3. æ²’æŠ“é
                if len(text) > 50 and any(k in text for k in ["å»ºè­°", "æˆ‘è¦ºå¾—", "å› ç‚º", "åˆ†æ‰‹", "å¦ä¸€åŠ"]):
                    if text not in seen_text:
                        # æ¸…æ´—æ–‡å­—ï¼šç§»é™¤éå¤šæ›è¡Œ
                        clean_text = text.replace("\n", " ")
                        mentor_dataset.append({
                            "instruction": "[äººæ ¼:æ„Ÿæƒ…å°å¸«] è«‹é‡å°ä»¥ä¸‹æƒ…æ„Ÿå…§å®¹é€²è¡Œåˆ†æä¸¦çµ¦å‡ºå»ºè­°ã€‚",
                            "input": f"æ–‡ç« å…§å®¹ï¼š{clean_text[:100]}...",
                            "output": clean_text
                        })
                        seen_text.add(text)
            
            # æ²å‹•ä¸¦éš¨æ©Ÿç­‰å¾…
            await page.evaluate("window.scrollBy(0, 1500)")
            await page.wait_for_timeout(3000)

        # å„²å­˜
        with open("threads_mentor_robust.jsonl", "w", encoding="utf-8") as f:
            for entry in mentor_dataset:
                f.write(json.dumps(entry, ensure_ascii=False) + "\n")
        
        print(f"ğŸ‰ æˆåŠŸï¼ç²å¾— {len(mentor_dataset)} ç­†çœŸå¯¦èªæ–™ã€‚")
        await browser.close()

if __name__ == "__main__":
    asyncio.run(scrape_threads_robust())